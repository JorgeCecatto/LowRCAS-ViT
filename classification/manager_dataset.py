from timm.data import create_transform
from torch.utils.data import Dataset
from typing import Any,Tuple
from sklearn.model_selection import train_test_split
import os
import torch
import torch.nn as nn
import numpy as np
from PIL import Image,ImageStat

def image_loader(img):
    return Image.open(img).convert("RGB")


class CustomDataset(Dataset):
    def __init__(self,dir,transform=None,target_transform=None,loader = None):
        self.main_dir = dir
        self.transform = transform
        self.target_transform = target_transform
        self.classes = [d.name for d in os.scandir(dir) if d.is_dir()]
        self.classes.sort()
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}
        self.targets = []
        self.instances = self.make_instances()
        self.loader = loader

        if loader is None:
            self.loader = lambda x: Image.open(x).convert('RGB')

    def make_instances(self):
        instances = []
        targets = []
        for target_class in sorted(self.class_to_idx.keys()):
                class_index = self.class_to_idx[target_class]
                target_dir = os.path.join(self.main_dir, target_class)
                for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):
                    for fname in sorted(fnames):
                        path = os.path.join(root, fname)
                        item = path, class_index
                        targets.append(class_index)
                        instances.append(item)
        self.targets = torch.tensor(targets)
        return instances
    def __getitem__(self,index:int) -> Tuple[Any,Any]:
        path, target = self.instances[index]
        instance = self.loader(path)
        if self.transform is not None:
            instance = self.transform(instance)
        if self.target_transform is not None:
            target = self.target_transform(target)
        return instance,target
    def __len__(self) -> int:
        return len(self.instances)

def get_tt_split(ds, bs):
    train_idx, temp_idx = train_test_split(np.arange(len(ds)),test_size=0.3,shuffle=True,stratify=ds.targets, random_state=42)
    valid_idx, test_idx = train_test_split(temp_idx,test_size=0.5,shuffle=True,stratify=ds.targets[temp_idx], random_state=42)

    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)
    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)
    test_sampler  = torch.utils.data.SubsetRandomSampler(test_idx)

    dl_train = torch.utils.data.DataLoader(ds,batch_size=bs,sampler=train_sampler)
    dl_valid = torch.utils.data.DataLoader(ds,batch_size=bs,sampler=valid_sampler)
    dl_test  = torch.utils.data.DataLoader(ds,batch_size=bs,sampler=test_sampler)

    return dl_train, dl_valid, dl_test